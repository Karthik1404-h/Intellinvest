{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d800419",
   "metadata": {},
   "source": [
    "# Portfolio Optimization with Machine Learning\n",
    "## Data Exploration and Analysis\n",
    "\n",
    "This notebook provides an interactive exploration of the portfolio optimization project data and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a9e32",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed stock data\n",
    "try:\n",
    "    processed_data_path = os.path.join(Config.PROCESSED_DATA_DIR, 'processed_stock_data.csv')\n",
    "    price_data = pd.read_csv(processed_data_path, index_col=0, header=[0, 1])\n",
    "    price_data.index = pd.to_datetime(price_data.index)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded price data: {price_data.shape}\")\n",
    "    print(f\"Date range: {price_data.index.min()} to {price_data.index.max()}\")\n",
    "    print(f\"Number of stocks: {len(price_data.columns.get_level_values(0).unique())}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Processed data not found. Please run data collection first.\")\n",
    "    print(\"Run: python ../main.py --step data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88562415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data info\n",
    "if 'price_data' in locals():\n",
    "    print(\"Stock symbols:\")\n",
    "    symbols = price_data.columns.get_level_values(0).unique()\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        if i % 8 == 0:\n",
    "            print()\n",
    "        print(f\"{symbol:<6}\", end=\" \")\n",
    "    \n",
    "    print(f\"\\n\\nData columns for each stock: {price_data.columns.get_level_values(1).unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d29ac",
   "metadata": {},
   "source": [
    "## 2. Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d037de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price trends for major stocks\n",
    "if 'price_data' in locals():\n",
    "    major_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA']\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, stock in enumerate(major_stocks):\n",
    "        if (stock, 'Close') in price_data.columns:\n",
    "            plt.subplot(2, 3, i+1)\n",
    "            \n",
    "            close_prices = price_data[stock]['Close']\n",
    "            plt.plot(close_prices.index, close_prices.values, linewidth=2)\n",
    "            plt.title(f'{stock} Stock Price')\n",
    "            plt.ylabel('Price ($)')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and visualize returns\n",
    "if 'price_data' in locals():\n",
    "    # Calculate returns for all stocks\n",
    "    returns_data = {}\n",
    "    \n",
    "    for symbol in price_data.columns.get_level_values(0).unique():\n",
    "        if (symbol, 'Close') in price_data.columns:\n",
    "            close_prices = price_data[symbol]['Close'].dropna()\n",
    "            returns = close_prices.pct_change().dropna()\n",
    "            returns_data[symbol] = returns\n",
    "    \n",
    "    returns_df = pd.DataFrame(returns_data)\n",
    "    \n",
    "    print(f\"Returns data shape: {returns_df.shape}\")\n",
    "    print(f\"\\nReturns summary statistics:\")\n",
    "    print(returns_df.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns distribution analysis\n",
    "if 'returns_df' in locals():\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot 1: Returns distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for stock in major_stocks:\n",
    "        if stock in returns_df.columns:\n",
    "            plt.hist(returns_df[stock].dropna(), bins=50, alpha=0.6, label=stock, density=True)\n",
    "    plt.title('Returns Distribution')\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Volatility over time (rolling)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for stock in major_stocks[:3]:  # Just show top 3 for clarity\n",
    "        if stock in returns_df.columns:\n",
    "            rolling_vol = returns_df[stock].rolling(60).std() * np.sqrt(252)\n",
    "            plt.plot(rolling_vol.index, rolling_vol.values, label=f'{stock} Volatility', linewidth=2)\n",
    "    plt.title('Rolling 60-Day Volatility (Annualized)')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Correlation heatmap\n",
    "    plt.subplot(2, 2, 3)\n",
    "    corr_matrix = returns_df[major_stocks].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Stock Returns Correlation')\n",
    "    \n",
    "    # Plot 4: Risk-Return scatter\n",
    "    plt.subplot(2, 2, 4)\n",
    "    annual_returns = returns_df.mean() * 252\n",
    "    annual_volatility = returns_df.std() * np.sqrt(252)\n",
    "    \n",
    "    plt.scatter(annual_volatility, annual_returns, s=60, alpha=0.7)\n",
    "    \n",
    "    # Annotate points\n",
    "    for i, stock in enumerate(annual_returns.index):\n",
    "        if stock in major_stocks:\n",
    "            plt.annotate(stock, (annual_volatility[stock], annual_returns[stock]),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    plt.xlabel('Annual Volatility')\n",
    "    plt.ylabel('Annual Return')\n",
    "    plt.title('Risk-Return Profile')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4161c9",
   "metadata": {},
   "source": [
    "## 3. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustering results\n",
    "try:\n",
    "    clustering_features_path = os.path.join(Config.FEATURES_DIR, 'clustering_features.csv')\n",
    "    cluster_assignments_path = os.path.join(Config.RESULTS_DIR, 'cluster_assignments_kmeans.csv')\n",
    "    \n",
    "    clustering_features = pd.read_csv(clustering_features_path, index_col=0)\n",
    "    cluster_assignments = pd.read_csv(cluster_assignments_path)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded clustering features: {clustering_features.shape}\")\n",
    "    print(f\"‚úÖ Loaded cluster assignments: {cluster_assignments.shape}\")\n",
    "    \n",
    "    # Show cluster distribution\n",
    "    cluster_counts = cluster_assignments['cluster'].value_counts().sort_index()\n",
    "    print(f\"\\nCluster distribution:\")\n",
    "    print(cluster_counts)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Clustering results not found. Please run clustering first.\")\n",
    "    print(\"Run: python ../main.py --step clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering results\n",
    "if 'clustering_features' in locals() and 'cluster_assignments' in locals():\n",
    "    # Merge features with cluster assignments\n",
    "    features_with_clusters = clustering_features.merge(\n",
    "        cluster_assignments.set_index('symbol'), \n",
    "        left_index=True, right_index=True, how='inner'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Risk-Return by cluster\n",
    "    plt.subplot(2, 3, 1)\n",
    "    scatter = plt.scatter(features_with_clusters['returns_std'], \n",
    "                         features_with_clusters['returns_mean'],\n",
    "                         c=features_with_clusters['cluster'], \n",
    "                         cmap='tab10', s=60, alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.xlabel('Return Std')\n",
    "    plt.ylabel('Return Mean')\n",
    "    plt.title('Risk-Return by Cluster')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Sharpe ratio by cluster\n",
    "    plt.subplot(2, 3, 2)\n",
    "    features_with_clusters.boxplot(column='sharpe_ratio', by='cluster', ax=plt.gca())\n",
    "    plt.title('Sharpe Ratio by Cluster')\n",
    "    plt.suptitle('')  # Remove automatic title\n",
    "    \n",
    "    # Plot 3: Market correlation by cluster\n",
    "    plt.subplot(2, 3, 3)\n",
    "    if 'market_correlation' in features_with_clusters.columns:\n",
    "        features_with_clusters.boxplot(column='market_correlation', by='cluster', ax=plt.gca())\n",
    "        plt.title('Market Correlation by Cluster')\n",
    "        plt.suptitle('')\n",
    "    \n",
    "    # Plot 4: Cluster composition pie chart\n",
    "    plt.subplot(2, 3, 4)\n",
    "    cluster_counts.plot(kind='pie', autopct='%1.1f%%', ax=plt.gca())\n",
    "    plt.title('Cluster Size Distribution')\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    # Plot 5: Feature importance heatmap\n",
    "    plt.subplot(2, 3, 5)\n",
    "    cluster_means = features_with_clusters.groupby('cluster').mean()\n",
    "    feature_cols = [col for col in cluster_means.columns if col != 'cluster']\n",
    "    sns.heatmap(cluster_means[feature_cols[:8]].T, annot=True, fmt='.3f', \n",
    "                cmap='RdYlBu_r', center=0, ax=plt.gca())\n",
    "    plt.title('Cluster Feature Means')\n",
    "    plt.xlabel('Cluster')\n",
    "    \n",
    "    # Plot 6: Sample stocks from each cluster\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    cluster_info = []\n",
    "    for cluster_id in sorted(features_with_clusters['cluster'].unique()):\n",
    "        cluster_stocks = features_with_clusters[features_with_clusters['cluster'] == cluster_id].index.tolist()\n",
    "        sample_stocks = cluster_stocks[:5]  # Show first 5 stocks\n",
    "        cluster_info.append(f\"Cluster {cluster_id}: {', '.join(sample_stocks)}\")\n",
    "    \n",
    "    plt.text(0.1, 0.9, '\\n'.join(cluster_info), transform=plt.gca().transAxes, \n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    plt.title('Sample Stocks by Cluster')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe637ee7",
   "metadata": {},
   "source": [
    "## 4. Portfolio Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f478992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimization results\n",
    "optimization_methods = ['mean_variance', 'risk_parity', 'min_variance', 'max_sharpe', 'cluster_based']\n",
    "portfolio_weights = {}\n",
    "optimization_summaries = {}\n",
    "\n",
    "for method in optimization_methods:\n",
    "    try:\n",
    "        weights_path = os.path.join(Config.RESULTS_DIR, f'portfolio_weights_{method}.csv')\n",
    "        summary_path = os.path.join(Config.RESULTS_DIR, f'optimization_summary_{method}.json')\n",
    "        \n",
    "        if os.path.exists(weights_path):\n",
    "            weights = pd.read_csv(weights_path, index_col=0, squeeze=True)\n",
    "            portfolio_weights[method] = weights\n",
    "        \n",
    "        if os.path.exists(summary_path):\n",
    "            import json\n",
    "            with open(summary_path, 'r') as f:\n",
    "                summary = json.load(f)\n",
    "            optimization_summaries[method] = summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load {method} results: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Loaded optimization results for {len(portfolio_weights)} methods\")\n",
    "print(f\"Methods: {list(portfolio_weights.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89219230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display optimization summary\n",
    "if optimization_summaries:\n",
    "    summary_df = pd.DataFrame(optimization_summaries).T\n",
    "    print(\"Portfolio Optimization Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(summary_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio weights\n",
    "if portfolio_weights:\n",
    "    n_methods = len(portfolio_weights)\n",
    "    cols = min(3, n_methods)\n",
    "    rows = (n_methods + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(5*cols, 4*rows))\n",
    "    \n",
    "    for i, (method, weights) in enumerate(portfolio_weights.items()):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        \n",
    "        # Show top 10 positions\n",
    "        top_weights = weights.nlargest(10)\n",
    "        \n",
    "        plt.barh(range(len(top_weights)), top_weights.values)\n",
    "        plt.yticks(range(len(top_weights)), top_weights.index)\n",
    "        plt.xlabel('Weight')\n",
    "        plt.title(f'{method.replace(\"_\", \" \").title()} - Top 10 Positions')\n",
    "        plt.gca().invert_yaxis()\n",
    "        \n",
    "        # Add weight labels\n",
    "        for j, v in enumerate(top_weights.values):\n",
    "            plt.text(v + 0.001, j, f'{v:.3f}', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba56354",
   "metadata": {},
   "source": [
    "## 5. Backtesting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load backtesting results\n",
    "try:\n",
    "    comparison_path = os.path.join(Config.RESULTS_DIR, 'strategy_comparison_summary.csv')\n",
    "    \n",
    "    if os.path.exists(comparison_path):\n",
    "        comparison_results = pd.read_csv(comparison_path, index_col=0)\n",
    "        print(\"‚úÖ Loaded backtesting comparison results\")\n",
    "        print(\"\\nStrategy Performance Comparison:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(comparison_results.round(4))\n",
    "        \n",
    "        # Highlight best performers\n",
    "        best_sharpe = comparison_results['Sharpe Ratio'].idxmax()\n",
    "        best_return = comparison_results['Annual Return'].idxmax()\n",
    "        \n",
    "        print(f\"\\nüèÜ Best Sharpe Ratio: {best_sharpe} ({comparison_results.loc[best_sharpe, 'Sharpe Ratio']:.4f})\")\n",
    "        print(f\"üèÜ Best Annual Return: {best_return} ({comparison_results.loc[best_return, 'Annual Return']:.4f})\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå Backtesting results not found. Please run backtesting first.\")\n",
    "        print(\"Run: python ../main.py --step backtesting\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading backtesting results: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot individual strategy returns\n",
    "strategy_returns = {}\n",
    "\n",
    "for method in optimization_methods:\n",
    "    try:\n",
    "        returns_path = os.path.join(Config.RESULTS_DIR, f'portfolio_values_{method}.csv')\n",
    "        if os.path.exists(returns_path):\n",
    "            returns = pd.read_csv(returns_path, index_col=0, squeeze=True)\n",
    "            returns.index = pd.to_datetime(returns.index)\n",
    "            strategy_returns[method] = returns\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "if strategy_returns:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Cumulative returns\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for method, returns in strategy_returns.items():\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        plt.plot(cumulative.index, cumulative.values, label=method.replace('_', ' ').title(), linewidth=2)\n",
    "    \n",
    "    plt.title('Cumulative Returns Comparison')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Rolling Sharpe\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for method, returns in strategy_returns.items():\n",
    "        rolling_sharpe = returns.rolling(60).apply(\n",
    "            lambda x: x.mean() / x.std() * np.sqrt(252) if x.std() != 0 else 0\n",
    "        )\n",
    "        plt.plot(rolling_sharpe.index, rolling_sharpe.values, \n",
    "                label=method.replace('_', ' ').title(), linewidth=2)\n",
    "    \n",
    "    plt.title('Rolling 60-Day Sharpe Ratio')\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Drawdown\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for method, returns in strategy_returns.items():\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        rolling_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - rolling_max) / rolling_max\n",
    "        plt.fill_between(drawdown.index, drawdown.values, 0, \n",
    "                        alpha=0.3, label=method.replace('_', ' ').title())\n",
    "    \n",
    "    plt.title('Drawdown Analysis')\n",
    "    plt.ylabel('Drawdown')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Returns distribution\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for method, returns in strategy_returns.items():\n",
    "        plt.hist(returns.dropna(), bins=30, alpha=0.6, density=True,\n",
    "                label=method.replace('_', ' ').title())\n",
    "    \n",
    "    plt.title('Returns Distribution')\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34130a",
   "metadata": {},
   "source": [
    "## 6. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66feec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "print(\"üìä PORTFOLIO OPTIMIZATION PROJECT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'price_data' in locals():\n",
    "    print(f\"üìà Data Coverage:\")\n",
    "    print(f\"   ‚Ä¢ {len(price_data.columns.get_level_values(0).unique())} stocks analyzed\")\n",
    "    print(f\"   ‚Ä¢ Date range: {price_data.index.min().strftime('%Y-%m-%d')} to {price_data.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"   ‚Ä¢ {len(price_data)} trading days\")\n",
    "\n",
    "if 'cluster_assignments' in locals():\n",
    "    print(f\"\\nüéØ Clustering Analysis:\")\n",
    "    print(f\"   ‚Ä¢ {len(cluster_assignments['cluster'].unique())} clusters identified\")\n",
    "    print(f\"   ‚Ä¢ Most common cluster: {cluster_assignments['cluster'].value_counts().index[0]} ({cluster_assignments['cluster'].value_counts().iloc[0]} stocks)\")\n",
    "    \n",
    "if optimization_summaries:\n",
    "    print(f\"\\n‚ö° Optimization Methods:\")\n",
    "    print(f\"   ‚Ä¢ {len(optimization_summaries)} methods implemented\")\n",
    "    \n",
    "    best_method = max(optimization_summaries.keys(), \n",
    "                     key=lambda x: optimization_summaries[x].get('sharpe_ratio', 0))\n",
    "    print(f\"   ‚Ä¢ Best ex-ante Sharpe: {best_method} ({optimization_summaries[best_method].get('sharpe_ratio', 0):.4f})\")\n",
    "\n",
    "if 'comparison_results' in locals():\n",
    "    print(f\"\\nüèÜ Backtesting Results:\")\n",
    "    best_sharpe_bt = comparison_results['Sharpe Ratio'].idxmax()\n",
    "    best_return_bt = comparison_results['Annual Return'].idxmax()\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Best backtested Sharpe: {best_sharpe_bt} ({comparison_results.loc[best_sharpe_bt, 'Sharpe Ratio']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Best backtested return: {best_return_bt} ({comparison_results.loc[best_return_bt, 'Annual Return']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Average max drawdown: {comparison_results['Max Drawdown'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"   ‚Ä¢ Machine learning enhanced portfolio optimization shows promise\")\n",
    "print(\"   ‚Ä¢ Stock clustering provides valuable diversification insights\")\n",
    "print(\"   ‚Ä¢ Multiple optimization methods offer different risk-return profiles\")\n",
    "print(\"   ‚Ä¢ Transaction costs and rebalancing frequency significantly impact performance\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   ‚Ä¢ Experiment with different ML models for return prediction\")\n",
    "print(\"   ‚Ä¢ Implement dynamic rebalancing based on market conditions\")\n",
    "print(\"   ‚Ä¢ Add alternative risk measures (VaR, CVaR)\")\n",
    "print(\"   ‚Ä¢ Include alternative assets (bonds, commodities, REITs)\")\n",
    "print(\"   ‚Ä¢ Test on out-of-sample periods for robust validation\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
